===================================START INTRO AND SUMMARY=============================================================
    This scratch.txt document will serve as the running notepad for the project. Other documentation may be written as
    time goes on and the project advances, but this scratch.txt will serve as the active notepad. Below will be notes on
    the compiler as a whole, as well as specific portions. Scanner, Parser, Linker, Assembly, etc. Each note entered
    will be dated and boxed off for the relevant time/date it was entered like so:

    Example:

    ===================================12/31/2017 - START - 08:57 - JRinderer:=========================================
        ******SUMMARY: Each section will contain a summary of the notes to follow. Today is Dec 31st 2017.
        ---------------------------------------------------------------------------------------------------------------
            -More Notes...
            -...
    ===================================12/31/2017 - END - 20:00 - JRinderer============================================

    If a day's notes are subdivided for that day the format below will be used.

    Example:

    ===================================12/31/2017 - START - 08:57 - JRinderer:=========================================
        ******SUMMARY: Each section will contain a summary of the notes to follow. Today is Dec 31st 2017.

            -Today is December 31st 2017 and this noted repeats this information
            -More Notes...
        ---------------------------------------------------------------------------------------------------------------
        ******SUMMARY: If the day's notes are subdivided then the format here will be used.
            -This is a sub section of today's notes.
            -This section will discuss the subdivision of notes.
    ===================================12/31/2017 - END - 20:00 - JRinderer============================================


    The format above will be followed throughout the notebook in order to break up time/dates and progress.

    When edits are made to previous notes (for example if I re-write my types and sub-divide the operators into multiple
    types they will be notated with in the START field, the edits will be made to the original with a **START DATE**
    at the beginning and a **END DATE** where the edits ended. A copy of the original (only where changes made) will be
    added to the bottom of that days note with the Original Date **ORIGINAL DATE and will be encolsed in *****

    Example:

    ===================================12/31/2017 - START - 09:01 - JRinderer **1/1/2018 JRinderer**:==================
        **START 1/1/2018**
        -Operators for KLUMP: These will need further work to break down into Sub groups mathematical vs operational
               Mathematical: These will perform basic math:
                    1. +
                    2. -
                    3. *
                    4. /
                    5. %
               Comparison: These will compare values:
                    6. <>
                    7. <
                    8. >
                    9. =
                    10. !=
        **END 1/1/2018**

        **ORIGINAL 12/31/2017 - JRinderer******************************************************************************
           -Operators for KLUMP: These will need further work to break down into Sub groups mathematical vs operational
               1. :
               2. ;
               3. .
               4. (
               5. )
               6. {
               7. }
               8. [
               9. ]
               10. #
        ***************************************************************************************************************
    ===================================12/31/2017 - END - 11:01 - JRinderer **1/1/2018 JRinderer**:====================
===================================END INTRO AND SUMMARY===============================================================
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
=======================================1/3/2018 - START - 13:10 - JRinderer============================================
    ********Summary:This is a rebuild of the sample code I found with a focus on re-writing the scanner portion to be
    easier to read with more functions to trim down and simplify. Scanner can currently scan for Words. Need to output
    to a .txt file.

        -As data is scanned in add it to a TOKEN & LEXEME field. Currently each data point is stored within a word or a
        number type. While we can loop through these values they need to be ordered as they appear. Doing this as the
        text is scanned ensures that the order is followed.

        -Regardless of Type store literal as LEXEME. Regardless of type store token as TOKEN. LEXEME and TOKEN are new
        arrays that will be populated with the respective TOKEN or LEXEME.

        -This allows us to store the values as they are scanned in, in the order in which they are scanned.

        -Once all the data is scanned in we can loop through the LEXEME and TOKEN fields and print them to a file.

        -General outline below:
            1. Scan through all characters.
            2. Determine if characters are words and if so are they KEYWORDS.
            3. Determine Token TYPES from words (KEYWORD, CONSTANT)
            4. Determine Token Types from chars (constants, identifiers)
            5. Determine Token Types from ints (constants[numbers], decimals [number.number]
            6. Determine Token Types from punctuations (consider making actual symbol (=(, {={, etc).
            7. Determine Token Types from Operators (>, <, <>, etc).

        -Based on the above critiera we can store the LEXEM and TOKEN type. Modify systemsdefs.h with the above data
        structures.
=======================================1/3/2018 - END - 21:11 - JRinderer==============================================
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
=======================================1/4/2018 - START - 11:00 - JRinderer============================================
    ********Summary: Program can now read KEYWORDS and CONSTANTS from words (not int's yet). Will print the TOKEN and
    the LEXEME. Need to format so that space between TOKEN and LEXEME is a standard length.

        -Next step is to scan NUMBERS in and assign their TOKEN type as NUMBER.
=======================================1/4/2018 - END 20:00 - JRinderer================================================
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
=======================================1/6/2018 - START - 19:00 JRinderer==============================================
    ********Summary: The program is reading int's but due to how I am printing them out INT's are getting missed in the
    output. This is resulting in the TOKEN and LEXEME not always matching in cases wheren number is missing. If you
    view the test.kl file you'll notice that there are three number constants. There are 3 additional tokens at the end
    missing their LEXEME. This is due to how the data is printed in C.
=======================================1/6/2018 - END - 21:00 - JRinderer==============================================
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
=======================================1/7/2018 - START 09:14 - JRinderer==============================================
    ********Summary: How the 2d arrays are built and what elements seems to be causing some issue. If I use numi and
    numj these start a 0 again, and thus will not match with the simple loop I built. Determining the best way to
    allocate size for the array's we'll use.

        -Structures - Restudy structures as it might be easier to assign data points based on a structure type.
        Currently using STRINGS to call out the TOKEN type and pulling the LEXEME in along with it.

        -Solutions to problem brought up in Summary. Drop wordi wordj numi numj variables. Keep a universal 2d array
        loop variable as this will make reading easier and understanding what's going on. Keeping two different like
        this can result in more confusing code. replaced wordi, wordj, numi, numj with intlArryi and intlArryj.

        -Fixing a standard distance between tabs from TOKEN     LEXEME. Issue is with larger words and the tabs being
        misaligned.

        -Dynamically assigning array's as the scanner combs through characters. Based on largest word and number of
        words contained in the source code file.

            -Requires a function to determine the size of continuous data. This must be stored for the LENGTH of
            individual words.

            -Requires a method/function to determine total characters in the source code file. This will be the MAX
            allowed characters, numbers, words etc.

            -Requires another function to allocate the new size of the array.

        -As of right now I can find KEYWORDS, CONSTANTS, and NUMBERS. They are labeled correctly with their appropriate
        TOKEN and LEXEME in the format I want.

        -Still need to grab operators and determine operators that do something from punctuations.

        -Getting Segmentation falut when I attempt to write to a file. This was due to a mistake in understanding how
        strcat worked. I was setting it as a variable when it's a function that applies a change to variables/strings/
        chars.

        -Program can now output to a text file in the project folder. Notes for future output destroy any existing file
        assuming the user does not need previous work. This ensures that the new file that's being concatenated to is
        fresh.

        -Next steps: make test to determine other TOKE types - operators, punctuation, etc.

=======================================1/7/2018 - END 18:11 - JRinderer================================================